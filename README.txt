- Data loading and caching with joblib
- Data preprocessing including handling missing values and feature engineering
- Model training and evaluation for both regression and classification tasks
- Visualization of data correlations using seaborn
- Saving trained models with joblib
- Generating submission files for predictions
- Stacking of top 3 models to improve prediction accuracy
- Hyperparameter search for each model to find the best parameters based on the dataset

## Files and Directories

- `Data_Editing_Helpers.py`: Contains helper functions for data loading, preprocessing, and visualization.
- `Main.ipynb`: Jupyter notebook for running the data science pipeline.
- `submission.csv`: Example submission file generated by the pipeline.

## Usage

1. Update `x_name` and `y_name` in `Main.ipynb` to specify the feature and target columns.
2. Set `is_regression` to `True` for regression tasks or `False` for classification tasks.
3. Run the notebook to train models and generate predictions.

## Future Work

- Implement randomForestRegressor for filling missing values.
- Add functionality to convert string data to ASCII values.

 