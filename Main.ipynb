{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data_Editing_Helpers as DEH\n",
    "import Classifier as CLS\n",
    "import Regressor as RGS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.ensemble import StackingRegressor, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading ##\n",
    "test = pd.read_csv(\"Data/test.csv\")\n",
    "train = pd.read_csv(\"Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'cuisine' # What you're trying to predict\n",
    "x_name = 'id' # User id. Drop this column\n",
    "\n",
    "# Set this to True if you want to run regression models, False for classification models\n",
    "is_regression = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31818 entries, 0 to 31817\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           31818 non-null  int64 \n",
      " 1   cuisine      31818 non-null  object\n",
      " 2   ingredients  31818 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 745.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7955 entries, 0 to 7954\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           7955 non-null   int64 \n",
      " 1   cuisine      7955 non-null   object\n",
      " 2   ingredients  7955 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 186.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " None,\n",
       "        id   cuisine                                        ingredients\n",
       " 0  786437     greek  romaine lettuce, black olives, grape tomatoes,...\n",
       " 1  524295  filipino  eggs, pepper, salt, mayonaise, cooking oil, gr...\n",
       " 2  524306    indian                  water, vegetable oil, wheat, salt\n",
       " 3  524307    indian  black pepper, shallots, cornflour, cayenne pep...\n",
       " 4  524308  jamaican  plain flour, sugar, butter, eggs, fresh ginger...,\n",
       "        id cuisine                                        ingredients\n",
       " 0  996716       X  black peppercorns, crushed red pepper, fresh g...\n",
       " 1  829945       X  eggs, zucchini, pinto beans, chorizo sausage, ...\n",
       " 2  829949       X  chicken broth, unsalted butter, garlic, ground...\n",
       " 3  829953       X  pistachios, carrots, sugar, raisins, cashew nu...\n",
       " 4  829954       X  jack cheese, cilantro sprigs, pumpkin seeds, c...,\n",
       " id             0\n",
       " cuisine        0\n",
       " ingredients    0\n",
       " dtype: int64,\n",
       " id             0\n",
       " cuisine        0\n",
       " ingredients    0\n",
       " dtype: int64,\n",
       "                   id\n",
       " count   31818.000000\n",
       " mean   482337.630618\n",
       " std    198042.365635\n",
       " min    100003.000000\n",
       " 25%    318386.000000\n",
       " 50%    536596.000000\n",
       " 75%    611907.250000\n",
       " max    829937.000000,\n",
       "                   id\n",
       " count    7955.000000\n",
       " mean   867877.778504\n",
       " std     22155.580650\n",
       " min    829945.000000\n",
       " 25%    848672.500000\n",
       " 50%    867992.000000\n",
       " 75%    887374.000000\n",
       " max    996716.000000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic info about datasets\n",
    "train_info = train.info()\n",
    "test_info = test.info()\n",
    "\n",
    "# Display first few rows\n",
    "train_head = train.head()\n",
    "test_head = test.head()\n",
    "\n",
    "# Check for missing values\n",
    "missing_values_train = train.isnull().sum()\n",
    "missing_values_test = test.isnull().sum()\n",
    "\n",
    "# Summary statistics\n",
    "train_description = train.describe()\n",
    "test_description = test.describe()\n",
    "\n",
    "train_info, test_info, train_head, test_head, missing_values_train, missing_values_test, train_description, test_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrangling ##\n",
    "#Future implementation will remove map_seasons and convert_strings_to_ascii\n",
    "train, test = DEH.map_seasons(train, test)\n",
    "\n",
    "#train = DEH.convert_strings_to_ascii(train)\n",
    "#test = DEH.convert_strings_to_ascii(test)\n",
    "#train, test = DEH.dropUnusedColumns(train, test, y_name, x_name)\n",
    "train = DEH.remove_blank_rows(train, y_name)\n",
    "train, test = DEH.fill_NA(train, test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 99 as a filler for NA's. Will change to use Random Forest for filling NA's \n",
    "train, test = DEH.fill_NA(train, test, fill=99)\n",
    "X_train, X_test, y_train, y_test = DEH.traintestslpit(train, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\scout\\anaconda3\\envs\\WebScraping\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier Started\n",
      "Best parameters Decision Tree: {'classifier__min_weight_fraction_leaf': 0.0, 'classifier__min_samples_split': 15, 'classifier__min_samples_leaf': 3, 'classifier__max_leaf_nodes': 25, 'classifier__max_depth': 5}\n",
      "Model saved to ./TrainedModels/decisiontreeClassifier.pkl\n",
      "Decision Tree Classifier Finished\n",
      "Decision Tree Classifier score: 30.955\n",
      "\n",
      "KNN Classifier Started\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split(', '))\n",
    "train_ingredients = vectorizer.fit_transform(train['ingredients'])\n",
    "test_ingredients = vectorizer.transform(test['ingredients'])\n",
    "\n",
    "train_ingredients_df = pd.DataFrame(train_ingredients.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "test_ingredients_df = pd.DataFrame(test_ingredients.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add id and cuisine columns back to train, id to test\n",
    "train = pd.concat([train[['id', 'cuisine']].reset_index(drop=True), train_ingredients_df], axis=1)\n",
    "test = pd.concat([test[['id']].reset_index(drop=True), test_ingredients_df], axis=1)\n",
    "\n",
    "# Now drop the original 'ingredients' column if it still exists\n",
    "if 'ingredients' in train.columns:\n",
    "    train = train.drop(columns=['ingredients'])\n",
    "if 'ingredients' in test.columns:\n",
    "    test = test.drop(columns=['ingredients'])\n",
    "\n",
    "# Now split into X/y for modeling\n",
    "X = train.drop(columns=['id', 'cuisine'])\n",
    "y = train['cuisine']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def evaluate_model(model_func, X_train, y_train, X_test, y_test, model_name, results, is_regression):\n",
    "    model = model_func(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    if is_regression:\n",
    "        score = r2_score(y_test, predictions) * 100\n",
    "    else:\n",
    "        score = accuracy_score(y_test, predictions) * 100\n",
    "    results.append({\"model\": model_name, \"score\": score, \"model_obj\": model})\n",
    "    print(f\"{model_name} score: {score:.3f}\")\n",
    "\n",
    "## Training Models ##\n",
    "results = []\n",
    "\n",
    "if is_regression:\n",
    "    evaluate_model(RGS.decisiontreeRegressor, X_train, y_train, X_test, y_test, \"Decision Tree Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.linearRegressor, X_train, y_train, X_test, y_test, \"Linear Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.ridgeRegressor, X_train, y_train, X_test, y_test, \"Ridge Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.lassoRegressor, X_train, y_train, X_test, y_test, \"Lasso Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.randomForestRegressor, X_train, y_train, X_test, y_test, \"Random Forest Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.gradientBoostingRegressor, X_train, y_train, X_test, y_test, \"Gradient Boosting Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.catBoostRegressor, X_train, y_train, X_test, y_test, \"Cat Boost Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.knnRegressor, X_train, y_train, X_test, y_test, \"KNN Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.xgBoostRegressor, X_train, y_train, X_test, y_test, \"XGBoost Regressor\", results, is_regression)\n",
    "\n",
    "else:\n",
    "    evaluate_model(CLS.decisiontreeClassifier, X_train, y_train, X_test, y_test, \"Decision Tree Classifier\", results, is_regression)\n",
    "    evaluate_model(CLS.knnClassifier, X_train, y_train, X_test, y_test, \"KNN Classifier\", results, is_regression)\n",
    "    evaluate_model(CLS.adaboostClassifier, X_train, y_train, X_test, y_test, \"AdaBoost Classifier\", results, is_regression)\n",
    "    evaluate_model(CLS.randomForestClassifier, X_train, y_train, X_test, y_test, \"Random Forest Classifier\", results, is_regression)\n",
    "    evaluate_model(CLS.gradientBoostingClassifier, X_train, y_train, X_test, y_test, \"Gradient Boosting Classifier\", results, is_regression)\n",
    "    evaluate_model(CLS.catBoostClassifier, X_train, y_train, X_test, y_test, \"CatBoost Classifier\", results, is_regression)\n",
    "    evaluate_model(CLS.xgBoostClassifier, X_train, y_train, X_test, y_test, \"XGBoost Classifier\", results, is_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the stacking model\n",
    "for model in results:\n",
    "    model['cv_score'] = cross_val_score(model['model_obj'], X_train, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "top_3_models = sorted(results, key=lambda x: x['cv_score'], reverse=True)[:3]\n",
    "\n",
    "# Create the stacking model\n",
    "if is_regression:\n",
    "    estimators = [(model['model'], model['model_obj']) for model in top_3_models]\n",
    "    stacking_model = StackingRegressor(estimators=estimators, final_estimator=Ridge(alpha=1.0))\n",
    "else:\n",
    "    estimators = [(model['model'], model['model_obj']) for model in top_3_models]\n",
    "    stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "stacking_predictions = stacking_model.predict(X_test)\n",
    "if is_regression:\n",
    "    stacking_score = r2_score(y_test, stacking_predictions) * 100\n",
    "else:\n",
    "    stacking_score = accuracy_score(y_test, stacking_predictions) * 100\n",
    "\n",
    "print(f\"Stacking Model score: {stacking_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the stacking model\n",
    "stacking_predictions_submission = stacking_model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 3 models\n",
    "print(\"Top 3 Models:\")\n",
    "for model in top_3_models:\n",
    "    print(f\"{model['model']}: {model['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file for submission\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "submission = pd.DataFrame({\n",
    "    x_name: test[x_name],\n",
    "    y_name: stacking_predictions_submission\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WebScraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
