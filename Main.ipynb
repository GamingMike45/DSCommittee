{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data_Editing_Helpers as DEH\n",
    "import Classifier as CLS\n",
    "import Regressor as RGS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import torch\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "import dill\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.ensemble import StackingRegressor, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Loading ##\n",
    "test = pd.read_csv(\"Data/test.csv\")\n",
    "train = pd.read_csv(\"Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'Sentiment1' # What you're trying to predict\n",
    "x_name = 'TonyID' # User id. Drop this column\n",
    "\n",
    "# Set this to True if you want to run regression models, False for classification models\n",
    "is_regression = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info about datasets\n",
    "train_info = train.info()\n",
    "test_info = test.info()\n",
    "\n",
    "# Display first few rows\n",
    "train_head = train.head()\n",
    "test_head = test.head()\n",
    "\n",
    "# Check for missing values\n",
    "missing_values_train = train.isnull().sum()\n",
    "missing_values_test = test.isnull().sum()\n",
    "\n",
    "# Summary statistics\n",
    "train_description = train.describe()\n",
    "test_description = test.describe()\n",
    "\n",
    "train_info, test_info, train_head, test_head, missing_values_train, missing_values_test, train_description, test_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrangling ##\n",
    "#Future implementation will remove map_seasons and convert_strings_to_ascii\n",
    "train, test = DEH.map_seasons(train, test)\n",
    "\n",
    "#train = DEH.convert_strings_to_ascii(train)\n",
    "#test = DEH.convert_strings_to_ascii(test)\n",
    "train, test = DEH.dropUnusedColumns(train, test, y_name, x_name)\n",
    "train = DEH.remove_blank_rows(train, y_name)\n",
    "train, test = DEH.fill_NA(train, test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "print(df_train.head(10))\n",
    "print(df_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    # Remove URLs, mentions, hashtags, punctuation\n",
    "    text = re.sub(r\"http\\S+|@\\S+|#\\S+|[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Text features\n",
    "X_text = df_train['SentimentText']\n",
    "y = df_train['Sentiment1']\n",
    "\n",
    "\n",
    "# Encode target labels (+/- to 0/1)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Apply cleaning\n",
    "X_text_cleaned = X_text.apply(clean_text)\n",
    "\n",
    "mask_nonempty = X_text_cleaned.str.strip() != \"\"\n",
    "X_text_cleaned = X_text_cleaned[mask_nonempty]\n",
    "y_encoded = y_encoded[mask_nonempty]\n",
    "\n",
    "# Keep only classes with at least 2 samples\n",
    "class_counts = pd.Series(y_encoded).value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "mask = np.isin(y_encoded, valid_classes)\n",
    "\n",
    "X_text_cleaned = X_text_cleaned[mask]\n",
    "y_encoded = y_encoded[mask]\n",
    "\n",
    "\n",
    "# Save full dataset for PyTorch models\n",
    "X_full_for_pytorch = X_text_cleaned.copy()\n",
    "y_full_for_pytorch = y_encoded.copy()\n",
    "\n",
    "\n",
    "# Train/test split (if needed)\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text_cleaned, y_encoded, test_size=0.2, random_state=1103, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Convert text to numeric vectors\n",
    "vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(X_train_text)  # sparse matrix\n",
    "X_test = vectorizer.transform(X_test_text)  \n",
    "\n",
    "if not is_regression:\n",
    "    print(\"\\nEncoding class labels for classification...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "\n",
    "print(X_text_cleaned.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Feature matrix shape: {X_train.shape}\")\n",
    "# Define evaluation function\n",
    "def evaluate_model(model_func, X_train, y_train, X_test, y_test, model_name, results, is_regression):\n",
    "    print(f\"\\nRunning {model_name} ...\")\n",
    "    start_time = time.time()\n",
    "    model = model_func(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    if is_regression:\n",
    "        score = r2_score(y_test, predictions) * 100\n",
    "    else:\n",
    "        score = accuracy_score(y_test, predictions) * 100\n",
    "        \n",
    "    results.append({\"model\": model_name, \"score\": score, \"model_obj\": model})\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{model_name} score: {score:.3f} (Time: {elapsed:.1f}s)\")\n",
    "\n",
    "\n",
    "# Define evaluation function for Pytorch models (ONLY TRAINING)\n",
    "def evaluate_model_pytorch(model_func, X_train, y_train, X_test, y_test, model_name, results, is_regression):\n",
    "    print(f\"\\nRunning {model_name} ...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fit model and get vectorizer\n",
    "    model, vectorizer = model_func(X_train, y_train)\n",
    "\n",
    "    def ensure_float32(X):\n",
    "        if X is None:\n",
    "            return None\n",
    "        if hasattr(X, \"toarray\"):  # handle sparse TF-IDF matrices\n",
    "            X = X.toarray()\n",
    "        return np.asarray(X, dtype=np.float32)\n",
    "\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{model_name} finished (Time: {elapsed:.1f}s) â€“ No test set provided\")\n",
    "\n",
    "\n",
    "\n",
    "## Training Models ##\n",
    "results = []\n",
    "\n",
    "if is_regression:\n",
    "    evaluate_model(RGS.decisiontreeRegressor, X_train, y_train, X_test, y_test, \"Decision Tree Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.linearRegressor, X_train, y_train, X_test, y_test, \"Linear Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.ridgeRegressor, X_train, y_train, X_test, y_test, \"Ridge Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.lassoRegressor, X_train, y_train, X_test, y_test, \"Lasso Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.randomForestRegressor, X_train, y_train, X_test, y_test, \"Random Forest Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.gradientBoostingRegressor, X_train, y_train, X_test, y_test, \"Gradient Boosting Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.catBoostRegressor, X_train, y_train, X_test, y_test, \"Cat Boost Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.knnRegressor, X_train, y_train, X_test, y_test, \"KNN Regressor\", results, is_regression)\n",
    "    evaluate_model(RGS.xgBoostRegressor, X_train, y_train, X_test, y_test, \"XGBoost Regressor\", results, is_regression)\n",
    "\n",
    "else:\n",
    "    # CPU / fast tree-based models\n",
    "    #evaluate_model(CLS.decisiontreeClassifier, X_train, y_train, X_test, y_test, \"Decision Tree Classifier\", results, is_regression)\n",
    "    #evaluate_model(CLS.extraTreesClassifier, X_train, y_train, X_test, y_test, \"ExtraTrees Classifier\", results, is_regression)\n",
    "    #evaluate_model(CLS.adaboostClassifier, X_train, y_train, X_test, y_test, \"AdaBoost Classifier\", results, is_regression)\n",
    "    \n",
    "    # GPU / fast boosted models\n",
    "    #evaluate_model(CLS.catBoostClassifier, X_train, y_train, X_test, y_test, \"CatBoost Classifier\", results, is_regression)\n",
    "    #evaluate_model(CLS.xgBoostClassifier, X_train, y_train, X_test, y_test, \"XGBoost Classifier\", results, is_regression)\n",
    "    \n",
    "    # Lightweight baseline models for stacking/meta-classification\n",
    "    #evaluate_model(CLS.logisticRegressionClassifier, X_train, y_train, X_test, y_test, \"Logistic Regression Classifier\", results, is_regression)\n",
    "    #evaluate_model(CLS.sgdClassifier, X_train, y_train, X_test, y_test, \"SGD Classifier\", results, is_regression)\n",
    "\n",
    "    # Just more models\n",
    "    # train_loss (down) good \n",
    "    # valid_acc (up) good\n",
    "    # valid_loss (down) good\n",
    "\n",
    "    #evaluate_model_pytorch(CLS.pytorchClassifier, X_full_for_pytorch, y_full_for_pytorch, X_test, y_test, \"PyTorch Classifier\", results, is_regression)\n",
    "    #evaluate_model_pytorch(CLS.pytorchDeepClassifier, X_full_for_pytorch, y_full_for_pytorch, X_test, y_test, \"PyTorch Deep Classifier\", results, is_regression)\n",
    "    #evaluate_model_pytorch(CLS.pytorchLSTMClassifier, X_full_for_pytorch, y_full_for_pytorch, X_test, y_test, \"PyTorch LSTM Classifier\", results, is_regression)\n",
    "    #Trains no issue but when loaded it bloats ram causing crashes\n",
    "    #evaluate_model_pytorch(CLS.pytorchCNNClassifier, X_full_for_pytorch, y_full_for_pytorch, X_test, y_test, \"PyTorch CNN Classifier\", results, is_regression)\n",
    "\n",
    "    print(\"Training Logistic Regression as meta-classifier for stacking...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model mapping (file associations)  \n",
    "model_mapping = {\n",
    "    # Regression\n",
    "    \"Decision Tree Regressor\": \"decisiontreeRegressor.pkl\",\n",
    "    \"Linear Regressor\": \"linearRegressor.pkl\",\n",
    "    \"Ridge Regressor\": \"ridgeRegressor.pkl\",\n",
    "    \"Lasso Regressor\": \"lassoRegressor.pkl\",\n",
    "    \"Random Forest Regressor\": \"randomForestRegressor.pkl\",\n",
    "    \"Gradient Boosting Regressor\": \"gradientBoostingRegressor.pkl\",\n",
    "    \"Cat Boost Regressor\": \"catBoostRegressor.pkl\",\n",
    "    \"KNN Regressor\": \"knnRegressor.pkl\",\n",
    "    \"XGBoost Regressor\": \"xgBoostRegressor.pkl\",\n",
    "\n",
    "    # Classifiers\n",
    "    \"Decision Tree Classifier\": \"decisiontreeClassifier.pkl\",\n",
    "    \"ExtraTrees Classifier\": \"extraTreesClassifier.pkl\",\n",
    "    \"AdaBoost Classifier\": \"adaModel.pkl\",\n",
    "    \"CatBoost Classifier\": \"catBoostClassifier.pkl\",\n",
    "    \"XGBoost Classifier\": \"xgBoostClassifier.pkl\",\n",
    "    \"Logistic Regression Classifier\": \"logisticRegressionClassifier.pkl\",\n",
    "    \"SGD Classifier\": \"sgdClassifier.pkl\",\n",
    "\n",
    "    # PyTorch models (note: still save as .pth)\n",
    "    \"PyTorch Classifier\": \"pytorchClassifier.pkl\",\n",
    "    \"PyTorch Deep Classifier\": \"pytorchDeepClassifier.pkl\",\n",
    "    \"PyTorch LSTM Classifier\": \"pytorchLSTMClassifier.pkl\",\n",
    "    \"PyTorch CNN Classifier\": \"pytorchCNNClassifier.pkl\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Models (Supports dill + local PyTorch classes)\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Loads either:\n",
    "      - A scikit-learn model (.pkl) saved with pickle or joblib\n",
    "      - A PyTorch model bundle (.pth) containing {\"model_state_dict\", \"full_model\", \"vocab\"}\n",
    "    \"\"\"\n",
    "    basepath = f'TrainedModels/{filename}'\n",
    "    weightpath = basepath.replace(\".pkl\", \".pth\")\n",
    "\n",
    "    # Case 1: scikit-learn model\n",
    "    if os.path.exists(basepath):\n",
    "        try:\n",
    "            with open(basepath, 'rb') as f:\n",
    "                return joblib.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename} via pickle: {e}\")\n",
    "            try:\n",
    "                with open(basepath, 'rb') as f:\n",
    "                    return pickle.load(f)\n",
    "            except Exception as e2:\n",
    "                print(f\"Failed to load {filename} via joblib: {e2}\")\n",
    "                return None\n",
    "\n",
    "    # Case 2: PyTorch model (saved using dill)\n",
    "    elif os.path.exists(weightpath):\n",
    "        print(f\"Detected PyTorch model bundle for {filename}, loading...\")\n",
    "        try:\n",
    "            bundle = torch.load(\n",
    "                weightpath,\n",
    "                map_location='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                pickle_module=dill\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename} with dill: {e}\")\n",
    "            return None\n",
    "\n",
    "        if isinstance(bundle, dict):\n",
    "            model = bundle.get(\"model_class\", None)\n",
    "            vocab = bundle.get(\"vocab\", None)\n",
    "            if model is not None:\n",
    "                # instantiate if it's a callable (e.g., a lambda returning the class)\n",
    "                if model is not None:\n",
    "                    # Case 1: if model is callable (e.g. lambda returning a class)\n",
    "                    if callable(model):\n",
    "                        model = model()\n",
    "\n",
    "                    # Case 2: if model is still a class type (e.g. <class 'SimpleNet'>)\n",
    "                    if isinstance(model, type):\n",
    "                        model = model()\n",
    "\n",
    "                    if \"model_state_dict\" in bundle:\n",
    "                        model.load_state_dict(bundle[\"model_state_dict\"])\n",
    "                    model.eval()\n",
    "                    print(f\"Successfully loaded full PyTorch model for {filename}\")\n",
    "                    return model, vocab\n",
    "            else:\n",
    "                print(f\"Bundle for {filename} missing 'model_class' key.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Unexpected bundle format for {filename}. Expected dict.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Warning: {filename} not found!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def encode_and_pad(X_text, vocab):\n",
    "    \"\"\"Tokenize, encode using vocab, and pad sequences for PyTorch models.\"\"\"\n",
    "    def tokenize(text):\n",
    "        return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "    tokenized = [tokenize(t) for t in X_text]\n",
    "    encoded = [torch.tensor([vocab.get(tok, 1) for tok in toks], dtype=torch.long) for toks in tokenized]\n",
    "    return pad_sequence(encoded, batch_first=True, padding_value=0)\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "results = []\n",
    "\n",
    "for model_name, filename in model_mapping.items():\n",
    "    loaded = load_model(filename)\n",
    "\n",
    "    # Handle tuple (torch model + vocab)\n",
    "    if isinstance(loaded, tuple):\n",
    "        model, vocab = loaded\n",
    "    else:\n",
    "        model = loaded\n",
    "        vocab = None\n",
    "\n",
    "    if model is None:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nLoaded {model_name} from disk\")\n",
    "\n",
    "    try:\n",
    "        # PyTorch models\n",
    "        if isinstance(model, torch.nn.Module):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                if vocab is not None:\n",
    "                    # Use raw text input specifically prepared for PyTorch\n",
    "                    X_test_pytorch = encode_and_pad(X_test_text, vocab)\n",
    "                    X_tensor = X_test_pytorch.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                    outputs = model(X_tensor)\n",
    "                    predictions = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "                    # Free GPU memory after evaluation\n",
    "                    del X_tensor, X_test_pytorch, outputs\n",
    "                    torch.cuda.empty_cache()\n",
    "                else:\n",
    "                    raise ValueError(f\"Vocab not found for {model_name}, cannot encode X_test.\")\n",
    "\n",
    "        # scikit-learn models\n",
    "        else:\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "        # Compute score\n",
    "        if is_regression:\n",
    "            score = r2_score(y_test, predictions) * 100\n",
    "        else:\n",
    "            score = accuracy_score(y_test, predictions) * 100\n",
    "\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"score\": score,\n",
    "            \"model_obj\": model,\n",
    "            \"vocab\": vocab\n",
    "        })\n",
    "\n",
    "        print(f\"{model_name} score: {score:.3f}\")\n",
    "\n",
    "        # Free memory for PyTorch model\n",
    "        if isinstance(model, torch.nn.Module):\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {e}\")\n",
    "\n",
    "print(f\"\\n{len(results)} models evaluated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModelWrapper:\n",
    "    def __init__(self, model, vectorizer):\n",
    "        self.model = model\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Vectorize text if needed\n",
    "        if isinstance(X[0], str):\n",
    "            X = self.vectorizer.transform(X).toarray().astype('float32')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(torch.tensor(X, dtype=torch.float32))\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1).numpy()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "# Split sklearn vs PyTorch models\n",
    "sklearn_models = [m for m in results if \"pytorch\" not in m[\"model\"].lower()]\n",
    "pytorch_model_files = [m for m in results if \"pytorch\" in m[\"model\"].lower()]\n",
    "\n",
    "print(\"\\nEvaluating Sklearn Models\")\n",
    "def evaluate_sklearn(models, X_test, y_test, is_regression=False):\n",
    "    for i, model in enumerate(models):\n",
    "        name = model['model']\n",
    "        obj = model['model_obj']\n",
    "        print(f\"Evaluating pretrained Sklearn model {i+1}/{len(models)}: {name}\")\n",
    "        try:\n",
    "            preds = obj.predict(X_test)\n",
    "            score = r2_score(y_test, preds)*100 if is_regression else accuracy_score(y_test, preds)*100\n",
    "            model['cv_score'] = score\n",
    "            print(f\"{name} test score: {score:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {name}: {e}\")\n",
    "            model['cv_score'] = None\n",
    "    return [m for m in models if m['cv_score'] is not None]\n",
    "\n",
    "sklearn_models = evaluate_sklearn(sklearn_models, X_test, y_test, is_regression)\n",
    "# Rebuild pytorch model file list safely\n",
    "pytorch_model_files = [\n",
    "    {\"model\": name, \"model_obj\": path}\n",
    "    for name, path in model_mapping.items()\n",
    "    if \"pytorch\" in name.lower()\n",
    "]\n",
    "# Rebuild pytorch model file list safely\n",
    "pytorch_model_files = []\n",
    "for name in model_mapping.keys():\n",
    "    if \"pytorch\" in name.lower():\n",
    "        file_path = model_mapping[name]\n",
    "        if not file_path.endswith(\".pth\"):\n",
    "            file_path = file_path.replace(\".pkl\", \".pth\")\n",
    "        if os.path.exists(f\"TrainedModels/{file_path}\"):\n",
    "            pytorch_model_files.append({\n",
    "                \"model\": name,\n",
    "                \"model_obj\": f\"TrainedModels/{file_path}\"\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: {file_path} not found in TrainedModels/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried to make it so this was not needed but oh well. Running out of time. \n",
    "# These come from your embeddings and dataset\n",
    "# Build embedding matrix first so models can use it directly\n",
    "\n",
    "def build_embedding_matrix(vocab, glove_path, embedding_dim):\n",
    "    print(\"Building embedding matrix...\")\n",
    "    embedding_matrix = torch.zeros(len(vocab), embedding_dim)\n",
    "    embeddings_index = {}\n",
    "\n",
    "    # Load GloVe embeddings\n",
    "    with open(glove_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vec = np.asarray(values[1:], dtype=\"float32\")\n",
    "            embeddings_index[word] = vec\n",
    "\n",
    "    # Fill embedding matrix\n",
    "    for word, idx in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[idx] = torch.tensor(embeddings_index[word])\n",
    "        else:\n",
    "            embedding_matrix[idx] = torch.randn(embedding_dim) * 0.1\n",
    "\n",
    "    print(f\"Embedding matrix built: {embedding_matrix.shape}\")\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "# === define embedding/dataset-related constants ===\n",
    "num_classes = len(np.unique(y))   # or y_train if you have it split\n",
    "embed_dim = 100                   # GloVe embedding dimension\n",
    "hidden_dim = 256                  # same as used during training\n",
    "glove_path = \"./glove.6B.100d.txt\"\n",
    "\n",
    "# Build embedding matrix before defining models\n",
    "embedding_matrix = build_embedding_matrix(vocab, glove_path, embed_dim)\n",
    "\n",
    "\n",
    "# === Model architectures ===\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            embedding_matrix, freeze=False, padding_idx=0\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim * 2),\n",
    "            nn.Linear(embed_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        emb = self.embedding(X)\n",
    "        mean_emb = emb.mean(dim=1)\n",
    "        max_emb = emb.max(dim=1).values\n",
    "        features = torch.cat([mean_emb, max_emb], dim=1)  # double embedding info\n",
    "        return self.fc(features)\n",
    "\n",
    "\n",
    "class DeepMLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            embedding_matrix, freeze=False, padding_idx=0\n",
    "        )\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        emb = self.embedding(X)\n",
    "        mean_emb = emb.mean(dim=1)\n",
    "        max_emb = emb.max(dim=1).values\n",
    "        features = torch.cat([mean_emb, max_emb], dim=1)  # double embedding info\n",
    "        return self.net(features)\n",
    "\n",
    "\n",
    "# Define LSTM model using embeddings\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            embedding_matrix, freeze=False, padding_idx=0\n",
    "        )\n",
    "        # match saved checkpoint from training (128 hidden, bidirectional)\n",
    "        self.lstm = nn.LSTM(embed_dim, 128, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(128 * 2, num_classes)  # 256 total features\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, X):\n",
    "        emb = self.embedding(X)\n",
    "        lstm_out, (h_n, _) = self.lstm(emb)\n",
    "        out = torch.cat((h_n[-2], h_n[-1]), dim=1)  # concat final states (bidirectional)\n",
    "        out = self.dropout(out)\n",
    "        return self.fc(out)\n",
    "\n",
    "\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            embedding_matrix, freeze=False, padding_idx=0\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(embed_dim, 64, kernel_size=3, padding=2, dilation=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 32, kernel_size=3, padding=2, dilation=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        emb = self.embedding(X)        # (batch, seq_len, embed_dim)\n",
    "        emb = emb.transpose(1, 2)      # (batch, embed_dim, seq_len)\n",
    "        feat = self.conv(emb).squeeze(-1)\n",
    "        return self.fc(feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating PyTorch Models\")\n",
    "pytorch_scores = []\n",
    "\n",
    "for idx, m in enumerate(pytorch_model_files):\n",
    "    name = m[\"model\"]\n",
    "    filename = m[\"model_obj\"]\n",
    "    print(f\"\\nLoading PyTorch model {idx+1}/{len(pytorch_model_files)}: {name}\")\n",
    "\n",
    "    try:\n",
    "        # Load bundle\n",
    "        if isinstance(filename, str) and os.path.exists(filename):\n",
    "            bundle = torch.load(filename, map_location='cpu', weights_only=False)\n",
    "            state_dict = bundle[\"model_state_dict\"]\n",
    "            vocab = bundle.get(\"vocab\", None)\n",
    "            model_class_lambda = bundle.get(\"model_class\", None)\n",
    "\n",
    "            if model_class_lambda is None:\n",
    "                print(f\"Warning: model_class not saved for {name}, cannot recreate model.\")\n",
    "                continue\n",
    "\n",
    "            # Call the lambda to get the model class or instance\n",
    "            if callable(model_class_lambda):\n",
    "                result = model_class_lambda()\n",
    "                \n",
    "                # Check if we got a class or an instance\n",
    "                if isinstance(result, type):\n",
    "                    # It's a class, we need to instantiate it\n",
    "                    print(f\"Lambda returned a class for {name}, instantiating...\")\n",
    "                    try:\n",
    "                        # Try without arguments first\n",
    "                        model_instance = result()\n",
    "                    except TypeError:\n",
    "                        # Needs arguments - infer from vocab and task\n",
    "                        vocab_size = len(vocab) if vocab else 10000\n",
    "                        num_classes = len(set(y_test)) if hasattr(y_test, '__iter__') else 2\n",
    "                        print(f\"Instantiating with vocab_size={vocab_size}, num_classes={num_classes}\")\n",
    "                        model_instance = result(vocab_size, num_classes)\n",
    "                elif isinstance(result, torch.nn.Module):\n",
    "                    # It's already an instance\n",
    "                    model_instance = result\n",
    "                else:\n",
    "                    raise TypeError(f\"Lambda returned unexpected type: {type(result)}\")\n",
    "            elif isinstance(model_class_lambda, torch.nn.Module):\n",
    "                # Already an instance\n",
    "                model_instance = model_class_lambda\n",
    "            else:\n",
    "                raise TypeError(f\"model_class is neither callable nor a Module: {type(model_class_lambda)}\")\n",
    "\n",
    "            # Verify valid model\n",
    "            if not isinstance(model_instance, torch.nn.Module):\n",
    "                raise TypeError(f\"{name} model_class did not produce a valid torch.nn.Module, got {type(model_instance)}\")\n",
    "\n",
    "            model_instance.load_state_dict(state_dict)\n",
    "\n",
    "        elif isinstance(filename, torch.nn.Module):\n",
    "            model_instance = filename\n",
    "            vocab = m.get(\"vocab\", None)\n",
    "        else:\n",
    "            raise ValueError(f\"{name} is neither a valid file path nor a model object.\")\n",
    "\n",
    "        # Move model to device\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model_instance = model_instance.to(device)\n",
    "        model_instance.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            print(f\"Encoding X_test_text for {name}...\")\n",
    "            X_test_tensor = encode_and_pad(X_test_text, vocab).to(device)\n",
    "            print(f\"Running forward pass for {name}...\")\n",
    "            outputs = model_instance(X_test_tensor)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        score = (\n",
    "            accuracy_score(y_test, preds) * 100\n",
    "            if not is_regression\n",
    "            else r2_score(y_test, preds) * 100\n",
    "        )\n",
    "        pytorch_scores.append(\n",
    "            {\n",
    "                \"model\": name,\n",
    "                \"score\": score,\n",
    "                \"state_dict\": model_instance.state_dict(),\n",
    "                \"vocab\": vocab,\n",
    "                \"model_class\": type(model_instance),\n",
    "            }\n",
    "        )\n",
    "        print(f\"{name} test score: {score:.3f}\")\n",
    "\n",
    "        # Free GPU memory\n",
    "        del model_instance, X_test_tensor, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Freed GPU memory for {name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load or evaluate {name}: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# manual map of model name -> class\n",
    "model_name_to_class = {\n",
    "    \"PyTorch Classifier\": SimpleNet,\n",
    "    \"PyTorch Deep Classifier\": DeepMLPNet,\n",
    "    \"PyTorch LSTM Classifier\": LSTMNet,\n",
    "    \"PyTorch CNN Classifier\": CNNNet,\n",
    "}\n",
    "\n",
    "pytorch_scores = []\n",
    "\n",
    "for idx, m in enumerate(pytorch_model_files):\n",
    "    name = m[\"model\"]\n",
    "    filename = m[\"model_obj\"]\n",
    "    print(f\"\\nLoading PyTorch model {idx+1}/{len(pytorch_model_files)}: {name}\")\n",
    "\n",
    "    try:\n",
    "        # Load bundle\n",
    "        bundle = torch.load(filename, map_location='cpu', weights_only=False)\n",
    "        state_dict = bundle['model_state_dict']\n",
    "        vocab = bundle.get('vocab', None)\n",
    "\n",
    "        # try to recreate model\n",
    "        model_cls = model_name_to_class.get(name, None)\n",
    "        if model_cls is None:\n",
    "            print(f\"Warning: no known class mapping for {name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Infer the number of classes from the state_dict\n",
    "        # Look for the final layer's output size\n",
    "        num_classes = None\n",
    "        vocab_size = len(vocab) if vocab else 10000\n",
    "        \n",
    "        # Check different possible final layer names\n",
    "        for key in state_dict.keys():\n",
    "            if 'fc.weight' in key or 'fc.4.weight' in key or 'net.8.weight' in key:\n",
    "                num_classes = state_dict[key].shape[0]\n",
    "                print(f\"Detected num_classes={num_classes} from state_dict key: {key}\")\n",
    "                break\n",
    "        \n",
    "        if num_classes is None:\n",
    "            print(f\"Warning: Could not infer num_classes for {name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Create model instance with correct parameters\n",
    "        try:\n",
    "            model_instance = model_cls(vocab_size, num_classes)\n",
    "        except TypeError:\n",
    "            # If the class doesn't accept these parameters, try without\n",
    "            model_instance = model_cls()\n",
    "        \n",
    "        if not isinstance(model_instance, torch.nn.Module):\n",
    "            raise TypeError(f\"{name} model_class mapping did not produce a valid torch.nn.Module\")\n",
    "\n",
    "        # load weights\n",
    "        model_instance.load_state_dict(state_dict)\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model_instance.to(device)\n",
    "        model_instance.eval()\n",
    "\n",
    "        # forward pass\n",
    "        with torch.no_grad():\n",
    "            print(f\"Encoding X_test_text for {name}...\")\n",
    "            X_test_tensor = encode_and_pad(X_test_text, vocab)  # keep on CPU first\n",
    "\n",
    "            all_preds = []\n",
    "            batch_size = 128  # adjust based on GPU memory\n",
    "\n",
    "            for i in range(0, len(X_test_tensor), batch_size):\n",
    "                batch = X_test_tensor[i:i+batch_size].to(device)\n",
    "                outputs = model_instance(batch)\n",
    "                preds_batch = outputs.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.append(preds_batch)\n",
    "\n",
    "            preds = np.concatenate(all_preds)\n",
    "\n",
    "        score = accuracy_score(y_test, preds)*100 if not is_regression else r2_score(y_test, preds)*100\n",
    "        pytorch_scores.append({\n",
    "            \"model\": name,\n",
    "            \"score\": score,\n",
    "            \"state_dict\": state_dict,\n",
    "            \"vocab\": vocab,\n",
    "            \"model_class\": model_cls\n",
    "        })\n",
    "        print(f\"{name} test score: {score:.3f}\")\n",
    "\n",
    "        del model_instance, X_test_tensor, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Freed GPU memory for {name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load or evaluate {name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare actual test data first\n",
    "print(\"\\nPreparing actual test data for predictions...\")\n",
    "x_name_values = test[x_name].values\n",
    "print(f\"Sample {x_name} values from test set: {x_name_values[:5]}\")\n",
    "X_test_actual = df_test['SentimentText']\n",
    "X_test_actual_cleaned = X_test_actual.apply(clean_text)\n",
    "X_test_actual_cleaned = X_test_actual_cleaned.apply(\n",
    "    lambda x: \"<UNK>\" if x.strip() == \"\" else x\n",
    ")\n",
    "\n",
    "# Select top 3 models\n",
    "top3_sklearn = sorted(sklearn_models, key=lambda x: x['cv_score'], reverse=True)[:3]\n",
    "top3_pytorch = sorted(pytorch_scores, key=lambda x: x['score'], reverse=True)[:3]\n",
    "\n",
    "print(\"\\nTop 3 sklearn models:\", [m['model'] for m in top3_sklearn])\n",
    "print(\"Top 3 PyTorch models:\", [m['model'] for m in top3_pytorch])\n",
    "\n",
    "print(\"\\nTraining Sklearn Stacked Model\")\n",
    "\n",
    "# Vectorize BOTH validation and actual test data\n",
    "print(\"Vectorizing validation data...\")\n",
    "X_val_vectorized = vectorizer.transform(X_test_text)  # For scoring\n",
    "print(\"Vectorizing actual test data...\")\n",
    "X_test_actual_vectorized = vectorizer.transform(X_test_actual_cleaned)  # For submission\n",
    "\n",
    "if is_regression:\n",
    "    sklearn_stack = StackingRegressor(\n",
    "        estimators=[(m['model'], m['model_obj']) for m in top3_sklearn],\n",
    "        final_estimator=Ridge(alpha=1.0),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    sklearn_stack = StackingClassifier(\n",
    "        estimators=[(m['model'], m['model_obj']) for m in top3_sklearn],\n",
    "        final_estimator=LogisticRegression(n_jobs=-1),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "print(\"Fitting sklearn stacked model...\")\n",
    "sklearn_stack.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on both validation and actual test\n",
    "sklearn_val_preds = sklearn_stack.predict(X_val_vectorized)\n",
    "sklearn_test_preds = sklearn_stack.predict(X_test_actual_vectorized)\n",
    "\n",
    "sklearn_score = r2_score(y_test, sklearn_val_preds)*100 if is_regression else accuracy_score(y_test, sklearn_val_preds)*100\n",
    "print(f\"Sklearn stacked validation score: {sklearn_score:.3f}\")\n",
    "\n",
    "print(\"\\nTraining PyTorch Stacked Meta Learner\")\n",
    "pytorch_val_matrix = []\n",
    "pytorch_test_matrix = []\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "for idx, m in enumerate(top3_pytorch):\n",
    "    model_class = m[\"model_class\"]\n",
    "    state_dict = m['state_dict']\n",
    "    vocab = m['vocab']\n",
    "    \n",
    "    # Infer num_classes from state_dict\n",
    "    num_classes = None\n",
    "    for key in state_dict.keys():\n",
    "        if 'fc.weight' in key or 'fc.4.weight' in key or 'net.8.weight' in key:\n",
    "            num_classes = state_dict[key].shape[0]\n",
    "            break\n",
    "    \n",
    "    if num_classes is None:\n",
    "        num_classes = len(set(y_test)) if hasattr(y_test, '__iter__') else 2\n",
    "    \n",
    "    if vocab is not None:\n",
    "        vocab_size = len(vocab)\n",
    "    else:\n",
    "        vocab_size = 20000\n",
    "    \n",
    "    try:\n",
    "        model_instance = model_class(vocab_size, num_classes)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            model_instance = model_class()\n",
    "        except:\n",
    "            print(f\"Could not instantiate {m['model']}, skipping...\")\n",
    "            continue\n",
    "    \n",
    "    model_instance.load_state_dict(state_dict)\n",
    "    model_instance = model_instance.to(device)\n",
    "    model_instance.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict on VALIDATION data (for scoring)\n",
    "        print(f\"Encoding validation data for {m['model']}...\")\n",
    "        X_val_tensor = encode_and_pad(X_test_text, vocab)\n",
    "        \n",
    "        all_val_preds = []\n",
    "        batch_size = 512\n",
    "        \n",
    "        for i in range(0, len(X_val_tensor), batch_size):\n",
    "            batch = X_val_tensor[i:i+batch_size]\n",
    "            if device == 'cuda':\n",
    "                batch = batch.pin_memory().to(device, non_blocking=True)\n",
    "            else:\n",
    "                batch = batch.to(device)\n",
    "            \n",
    "            outputs = model_instance(batch)\n",
    "            preds_batch = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_val_preds.append(preds_batch)\n",
    "            del batch, outputs\n",
    "        \n",
    "        val_preds = np.concatenate(all_val_preds)\n",
    "        pytorch_val_matrix.append(val_preds)\n",
    "        del X_val_tensor\n",
    "        \n",
    "        # Predict on ACTUAL TEST data (for submission)\n",
    "        print(f\"Encoding actual test data for {m['model']}...\")\n",
    "        X_test_actual_tensor = encode_and_pad(X_test_actual_cleaned, vocab)\n",
    "        \n",
    "        all_test_preds = []\n",
    "        \n",
    "        print(f\"Processing {len(X_test_actual_tensor)} test samples...\")\n",
    "        for i in range(0, len(X_test_actual_tensor), batch_size):\n",
    "            batch = X_test_actual_tensor[i:i+batch_size]\n",
    "            if device == 'cuda':\n",
    "                batch = batch.pin_memory().to(device, non_blocking=True)\n",
    "            else:\n",
    "                batch = batch.to(device)\n",
    "            \n",
    "            outputs = model_instance(batch)\n",
    "            preds_batch = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_test_preds.append(preds_batch)\n",
    "            del batch, outputs\n",
    "            \n",
    "            if (i // batch_size) % 100 == 0:\n",
    "                print(f\"  Processed {i}/{len(X_test_actual_tensor)} samples...\")\n",
    "        \n",
    "        test_preds = np.concatenate(all_test_preds)\n",
    "        pytorch_test_matrix.append(test_preds)\n",
    "        del X_test_actual_tensor\n",
    "\n",
    "    del model_instance\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Completed predictions for {m['model']}\")\n",
    "\n",
    "pytorch_val_matrix = np.column_stack(pytorch_val_matrix)\n",
    "pytorch_test_matrix = np.column_stack(pytorch_test_matrix)\n",
    "print(f\"PyTorch validation matrix shape: {pytorch_val_matrix.shape}\")\n",
    "print(f\"PyTorch test matrix shape: {pytorch_test_matrix.shape}\")\n",
    "\n",
    "if is_regression:\n",
    "    pytorch_meta = Ridge(alpha=1.0)\n",
    "else:\n",
    "    pytorch_meta = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "\n",
    "print(\"Fitting PyTorch meta learner on validation data...\")\n",
    "pytorch_meta.fit(pytorch_val_matrix, y_test)\n",
    "\n",
    "# Get predictions on both\n",
    "pytorch_val_preds = pytorch_meta.predict(pytorch_val_matrix)\n",
    "pytorch_test_preds = pytorch_meta.predict(pytorch_test_matrix)\n",
    "\n",
    "pytorch_score = r2_score(y_test, pytorch_val_preds)*100 if is_regression else accuracy_score(y_test, pytorch_val_preds)*100\n",
    "print(f\"PyTorch stacked validation score: {pytorch_score:.3f}\")\n",
    "\n",
    "print(\"\\nTraining Combined Stack\")\n",
    "combined_val_matrix = np.column_stack([sklearn_val_preds, pytorch_val_preds])\n",
    "combined_test_matrix = np.column_stack([sklearn_test_preds, pytorch_test_preds])\n",
    "\n",
    "print(f\"Combined validation matrix shape: {combined_val_matrix.shape}\")\n",
    "print(f\"Combined test matrix shape: {combined_test_matrix.shape}\")\n",
    "\n",
    "if is_regression:\n",
    "    combined_meta = Ridge(alpha=1.0)\n",
    "else:\n",
    "    combined_meta = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "\n",
    "print(\"Fitting combined stacked model on validation data...\")\n",
    "combined_meta.fit(combined_val_matrix, y_test)\n",
    "\n",
    "# Get predictions on both\n",
    "combined_val_preds = combined_meta.predict(combined_val_matrix)\n",
    "combined_test_preds = combined_meta.predict(combined_test_matrix)\n",
    "\n",
    "combined_score = r2_score(y_test, combined_val_preds)*100 if is_regression else accuracy_score(y_test, combined_val_preds)*100\n",
    "print(f\"Combined stacked validation score: {combined_score:.3f}\")\n",
    "\n",
    "# Convert predictions to +/- format\n",
    "def convert_to_sentiment(predictions):\n",
    "    \"\"\"Convert numeric predictions to +/- format\"\"\"\n",
    "    return ['+' if pred == 1 else '-' for pred in predictions]\n",
    "\n",
    "\n",
    "print(\"\\nSaving tab-delimited submission files...\")\n",
    "\n",
    "# Convert ALL TEST predictions to sentiment\n",
    "sklearn_test_sentiment = convert_to_sentiment(sklearn_test_preds)\n",
    "pytorch_test_sentiment = convert_to_sentiment(pytorch_test_preds)\n",
    "combined_test_sentiment = convert_to_sentiment(combined_test_preds)\n",
    "\n",
    "# Create DataFrames for ALL THREE submissions\n",
    "submission_sklearn = pd.DataFrame({\n",
    "    \"ID#\": x_name_values,\n",
    "    \"sentiment\": sklearn_test_sentiment\n",
    "})\n",
    "\n",
    "submission_pytorch = pd.DataFrame({\n",
    "    \"ID#\": x_name_values,\n",
    "    \"sentiment\": pytorch_test_sentiment\n",
    "})\n",
    "\n",
    "submission_combined = pd.DataFrame({\n",
    "    \"ID#\": x_name_values,\n",
    "    \"sentiment\": combined_test_sentiment\n",
    "})\n",
    "\n",
    "# Save ALL THREE tab-delimited text files\n",
    "submission_sklearn.to_csv(\"submission_sklearn_stacked.txt\", sep='\\t', index=False)\n",
    "submission_pytorch.to_csv(\"submission_pytorch_stacked.txt\", sep='\\t', index=False)\n",
    "submission_combined.to_csv(\"submission_combined_stacked.txt\", sep='\\t', index=False)\n",
    "\n",
    "print(\"All 3 tab-delimited submission files saved!\")\n",
    "print(f\"\\nTotal test predictions: {len(x_name_values)}\")\n",
    "print(\"\\nSample of sklearn submission:\")\n",
    "print(submission_sklearn.head(10))\n",
    "print(\"\\nSample of pytorch submission:\")\n",
    "print(submission_pytorch.head(10))\n",
    "print(\"\\nSample of combined submission:\")\n",
    "print(submission_combined.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAtaStuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
